<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="author" content="Wu De"/><meta name="keyword"/><meta name="description" content="基础算法动态规划基于动态规划的强化学习算法适用于白盒环境，事先知道P（状态转移矩阵）与r（reward），不需要进行交互。 动态规划分为两步  策略迭代 策略评估 $$V(s) \leftarrow r(s,\pi(s))+\gamma \sum_{s’}{P(s’|s, \pi(s))V(s’)} $$ 策略提升 $$\pi(s) \leftarrow argmax_a r(s,a)+\gamm">
<meta property="og:type" content="article">
<meta property="og:title" content="RL notes 2">
<meta property="og:url" content="https://dyrc9.github.io/2025/07/20/RL-notes-2/index.html">
<meta property="og:site_name" content="Sine&#39; Website">
<meta property="og:description" content="基础算法动态规划基于动态规划的强化学习算法适用于白盒环境，事先知道P（状态转移矩阵）与r（reward），不需要进行交互。 动态规划分为两步  策略迭代 策略评估 $$V(s) \leftarrow r(s,\pi(s))+\gamma \sum_{s’}{P(s’|s, \pi(s))V(s’)} $$ 策略提升 $$\pi(s) \leftarrow argmax_a r(s,a)+\gamm">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-07-20T04:54:49.000Z">
<meta property="article:modified_time" content="2025-07-20T04:55:28.249Z">
<meta property="article:author" content="Wu De">
<meta name="twitter:card" content="summary"><title>RL notes 2 - MEOW - 可爱明亮</title><link rel="shortcut icon" href="/img/site-icon.png">
<link rel="stylesheet" href="/css/style.css" id="dm-light">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/6.4.2/css/all.min.css">

<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
<meta name="generator" content="Hexo 7.3.0"></head><body><header><div class="top-nav" ondblclick="scrollToTop()"><div class="nav-info"><div class="nav-icon"><img id="nav-icon" src="/img/site-icon.png"/></div><div class="nav-title"><a id="nav-title" href="/" title="主页">Sine' Website</a></div></div><div class="nav-ribbon"><div class="top-menu-expanded"><a class="top-menu-item" href="/archives"><span>归档</span></a><a class="top-menu-item" href="/categories"><span>分类</span></a><a class="top-menu-item" href="/tags"><span>标签</span></a><a class="top-menu-item" href="/about"><span>关于</span></a></div><div class="top-search" onclick="toggleSearchWindow()"><div id="top-search-btn" title="搜索"><i class="icon fa-solid fa-magnifying-glass"></i><span>搜索</span></div></div><div id="top-menu-btn" onclick="openTopMenu()" title="打开菜单"><i class="fa-solid fa-bars fa-lg"></i></div></div></div></header><div id="top-menu-hidden"><div class="menu-hidden-content"><div class="menu-hidden-nav"><a class="menu-hidden-item" href="/archives"><i class="fa-solid fa-box-archive fa-sm"></i><span>归档</span></a><a class="menu-hidden-item" href="/categories"><i class="fa-regular fa-folder-open fa-sm"></i><span>分类</span></a><a class="menu-hidden-item" href="/tags"><i class="fa-solid fa-tags fa-sm"></i><span>标签</span></a><a class="menu-hidden-item" href="/about"><i class="fa-solid fa-paw fa-sm"></i><span>关于</span></a></div></div><div class="menu-hidden-blank" onclick="closeTopMenu()"></div></div>
<div class="blog-info"><div class="blog-pic"><img id="blog-pic" src="/img/site-icon.png"/></div><div class="blog-title"><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i><span>MEOW</span><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i></div><div class="blog-desc">但愿人长久，千里共婵娟</div></div><div class="main"><div class="main-content"><article class="post"><div class="post-title"><h1><i class="fa-solid fa-paw"></i>RL notes 2</h1></div><div class="post-info"><div class="post-info-first-line"><div class="post-date"><i class="icon fa-regular fa-calendar-plus" title="发布日期"></i><time class="publish-time">2025-07-20</time><i class="icon fa-regular fa-calendar-check" title="更新日期"></i><time class="update-time">2025-07-20</time></div>

</div><div class="post-info-second-line"><div class="post-copyright"><i class="icon fa-brands fa-creative-commons" title="版权声明"></i><span>版权声明: </span><a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh-hans" title="CC BY-NC-ND 4.0">署名-非商业性使用-禁止演绎 4.0</a></div>
<div class="post-word-count"><i class="icon fa-solid fa-pen-to-square"></i><span>全文约0.9K字</span></div><div class="pageview-post"><i class="icon fa-regular fa-eye"></i><span id="busuanzi_container_page_pv">阅读次数: <span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner"></i></span></span></div></div></div><div class="post-content"><h2 id="基础算法"><a href="#基础算法" class="headerlink" title="基础算法"></a>基础算法</h2><h3 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h3><p>基于动态规划的强化学习算法适用于白盒环境，事先知道P（状态转移矩阵）与r（reward），不需要进行交互。</p>
<p>动态规划分为两步</p>
<ul>
<li>策略迭代<ul>
<li>策略评估 $$V(s) \leftarrow r(s,\pi(s))+\gamma \sum_{s’}{P(s’|s, \pi(s))V(s’)} $$</li>
<li>策略提升 $$\pi(s) \leftarrow argmax_a r(s,a)+\gamma \sum_{s’}{P(s’|s, \pi(s))V(s’)}$$</li>
</ul>
</li>
<li>价值迭代 $$V(s) \leftarrow max_a {r(s,a)+\gamma \sum_{s’}{P(s’|s, \pi(s))V(s’)}}$$ 不显式更新策略$\pi$</li>
</ul>
<p>价值迭代采用了Bellman Optimality Equation</p>
<h3 id="时序差分"><a href="#时序差分" class="headerlink" title="时序差分"></a>时序差分</h3><p>TD: temporal difference基于时序差分的强化学习算法<br>并不事先知道P，需要和环境交互</p>
<ul>
<li>Sarsa 名字由来为用到了$s, a, r, s, a’$<ul>
<li>$Q(s,a) \leftarrow Q(s,a)+\alpha [r+\gamma Q(s’,a’) - Q(s,a)]$</li>
<li>采用$\epsilon-greedy$策略选择a及a’ 防止有些动作从未出现过</li>
<li>更为保守 （悬崖上倾向于离悬崖更远走）</li>
</ul>
</li>
<li>Q-learning <ul>
<li>$Q(s,a) \leftarrow Q(s,a)+\alpha [r+\gamma maxQ(s’,a’) - Q(s,a)]$</li>
<li>只采用$\epsilon-greedy$策略选择a而不选择a’</li>
</ul>
</li>
</ul>
<p>在这一节定义了在线和离线策略学习</p>
<ul>
<li>在线策略学习 on-policy 自来水 sarsa</li>
<li>离线策略学习 off-policy 脸盆 具有更小的样本复杂度 Q-learning</li>
</ul>
<p>采用数据的策略为行为策略(behavior policy) 更新的策略为目标策略(target policy)</p>
<p>当行为策略与目标策略一致时即为在线策略 不一致时即为离线策略</p>
<h3 id="Dyna-Q"><a href="#Dyna-Q" class="headerlink" title="Dyna-Q"></a>Dyna-Q</h3><p>基于模型但是环境模型通过采样估计得到 由Q-learning+Q-planning得到<br>略</p>
<h2 id="进阶算法"><a href="#进阶算法" class="headerlink" title="进阶算法"></a>进阶算法</h2><h3 id="DQN-深度强化学习的开端"><a href="#DQN-深度强化学习的开端" class="headerlink" title="DQN 深度强化学习的开端"></a>DQN 深度强化学习的开端</h3><p>DQN: Deep Q Network<br>前述方法均采用表格的形式记录Q 一个s,a对对应一个价值Q 仅适用于离散有限情况<br>采用神经网络表示Q 无限s,a对 由更新Q变为训练Q<br>Q-Learning: $Q(s,a) \leftarrow Q(s,a)+\alpha [r+\gamma \max_{a’ \in A} Q(s’,a’) - Q(s,a)]$</p>
<p>即定义Q网络损失函数 $$w^* &#x3D; \arg \min_{w}{\frac{1}{2N} \sum_{i&#x3D;1}^N[Q_w(s_i,a_i)-(r_i+\gamma \max_{a’ \in A} Q_w(s_i’,a’))]^2} $$</p>
<p>DQN还有两个关键模块</p>
<ul>
<li>经验回放——使样本满足独立假设<ul>
<li>非独立同分布的数据对训练神经网络影响大</li>
<li>MDP交互数据：该时刻的状态与上时刻有关</li>
<li>事实上这一手段并没有完全解决独立同分布的问题 只是缓解</li>
</ul>
</li>
<li>目标网络<ul>
<li>解决不稳定问题——目标包括输出</li>
<li>自举效应（Bootstrapping）</li>
<li>采用两个网络分别计算$Q_w(s_i,a_i)$与$r_i+\gamma \max_{a’ \in A} Q(s_i’,a’))$——训练网络$Q_w$与目标网络$Q_{w^-}$</li>
</ul>
</li>
</ul>
<p>DQN的改进：</p>
<ul>
<li>Double DQN<ul>
<li>DQN对Q有过高估计overestimaion</li>
<li>使动作选取依靠训练网络 将$\max_{a’ \in A} Q_{w^-}(s_i’,a’)$替换为$\max_{a’ \in A} Q_{w^-}(s_i’, \arg \max_{a’}Q_w(s’,a’))$</li>
</ul>
</li>
<li><h2 id="Dueling-DQN-定义优势函数-将V与A分别建模"><a href="#Dueling-DQN-定义优势函数-将V与A分别建模" class="headerlink" title="Dueling DQN  - 定义优势函数  - 将V与A分别建模"></a>Dueling DQN<br>  - 定义优势函数<br>  - 将V与A分别建模</h2></li>
</ul>
<h3 id="策略梯度-由基于价值到基于策略"><a href="#策略梯度-由基于价值到基于策略" class="headerlink" title="策略梯度 由基于价值到基于策略"></a>策略梯度 由基于价值到基于策略</h3><p>策略学习目标函数 $J(\theta)&#x3D;\mathbb{E}(V^{\pi_\theta}(s_0))$</p>
<p>策略梯度定理 $$\nabla J(\theta) \propto \sum_{s \in S} v^{\pi_{\theta}}(s)\sum_{a \in A}Q^{\pi_\theta}(s,a) \nabla_\theta \pi_\theta(a|s)$$</p>
<p>将V与Q的关系代入上式$$上式&#x3D;\mathbb{E}[Q^{\pi_\theta}(s,a) \nabla_\theta \log \pi_\theta(a|s)]$$</p>
<p>采样与更新一致 属于在线策略</p>
<p>关键是要对$Q^{\pi_\theta}(s,a)$进行估计 用蒙特卡洛方法进行估计——REINFORCE</p>
</div><div class="post-end"><div class="post-prev"></div><div class="post-next"><a href="/2025/02/19/MIG-research/" title="下一篇文章"><i class="fa-solid fa-chevron-right fa-lg"></i></a></div></div></article><div class="comment" id="comment"><script src="https://giscus.app/client.js" async="async"></script></div><div id="post-toc"><aside class="toc-aside"><div class="toc-title"><span><i class="fa-solid fa-paw"></i>目录</span></div><div class="toc-container" id="toc-body"><ol class="toc-content"><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95"><span class="toc-content-number">1.</span> <span class="toc-content-text">基础算法</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92"><span class="toc-content-number">1.1.</span> <span class="toc-content-text">动态规划</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86"><span class="toc-content-number">1.2.</span> <span class="toc-content-text">时序差分</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#Dyna-Q"><span class="toc-content-number">1.3.</span> <span class="toc-content-text">Dyna-Q</span></a></li></ol></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#%E8%BF%9B%E9%98%B6%E7%AE%97%E6%B3%95"><span class="toc-content-number">2.</span> <span class="toc-content-text">进阶算法</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#DQN-%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BC%80%E7%AB%AF"><span class="toc-content-number">2.1.</span> <span class="toc-content-text">DQN 深度强化学习的开端</span></a></li></ol></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#Dueling-DQN-%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8A%BF%E5%87%BD%E6%95%B0-%E5%B0%86V%E4%B8%8EA%E5%88%86%E5%88%AB%E5%BB%BA%E6%A8%A1"><span class="toc-content-number">3.</span> <span class="toc-content-text">Dueling DQN  - 定义优势函数  - 将V与A分别建模</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6-%E7%94%B1%E5%9F%BA%E4%BA%8E%E4%BB%B7%E5%80%BC%E5%88%B0%E5%9F%BA%E4%BA%8E%E7%AD%96%E7%95%A5"><span class="toc-content-number">3.1.</span> <span class="toc-content-text">策略梯度 由基于价值到基于策略</span></a></li></ol></li></ol></div></aside><div class="toc-blank" onclick="tocToggle()"></div></div></div></div><div id="tool-bar"><div id="tool-bar-main"><div id="tool-toggle" onclick="toolToggle()" title="设置"><i class="fa-solid fa-gear"></i></div><div id="toc-toggle" onclick="tocToggle()" title="目录"><i class="fa-solid fa-list-ul"></i></div><div id="go-to-comment" onclick="gotoComment()" title="评论"><i class="fa-regular fa-message fa-flip-horizontal"></i></div><div id="back-to-top" onclick="scrollToTop()" title="返回顶部"><i class="fa-solid fa-chevron-up"></i></div></div><div id="tool-bar-more" style="display: none;"><div id="darkmode-switch" onclick="darkmodeSwitch()" title="深色模式"><i class="fa-solid fa-circle-half-stroke"></i></div><div id="font-size-increase" onclick="fontSizeIncrease()" title="放大字体"><i class="fa-solid fa-plus"></i></div><div id="font-size-decrease" onclick="fontSizeDecrease()" title="缩小字体"><i class="fa-solid fa-minus"></i></div></div></div><div id="search-panel"><div class="search-container"><div class="search-head"><div class="search-title"><span><i class="fa-solid fa-paw"></i>搜索</span></div><div class="search-close-btn" onclick="toggleSearchWindow()"><i class="fa-regular fa-circle-xmark"></i></div></div><div class="search-box"><i class="fa-solid fa-magnifying-glass"></i><input id="search-input" type="text" placeholder="请输入需要搜索的内容……" value=""/></div><div class="search-body"><div id="search-count">匹配结果数: </div><div id="search-result"></div><div id="search-result-empty">未搜索到匹配的文章。</div></div></div></div><footer><div class="footer-content"><div class="copyright-info"><i class="fa-regular fa-copyright fa-xs"></i><span>2025 </span><a href="/about">Wu De</a><i class="fa-solid fa-cat fa-sm"></i><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo</a><span> &amp; </span><a href="https://github.com/chanwj/hexo-theme-meow" target="_blank" title="v2.1.2">Theme Meow</a></div><div class="pageview-site"><span id="busuanzi_container_site_pv">总访问量 : <span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner"></i></span></span><span id="busuanzi_container_site_uv">总访客数 : <span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner"></i></span></span></div></div></footer>
<script>const GLOBAL_CONFIG = {
  comment: { theme: ''}
}
</script>
<script src="/js/third-party/darkmode.js"></script>
<script>var options = {
  dark: '/css/darkmode.css',
  startAt: '24:00',
  endAt: '06:00',
  checkSystemScheme: 'false',
  saveOnToggle: 'true'
};
var darkMode = new DarkMode(options);
// change comment theme synchronously 同步修改评论区主题
if (darkMode.getMode() == "dark" && (true || true)) {
  if (document.getElementById('comment')) {
    document.getElementById('comment').getElementsByTagName('script')[0].setAttribute('data-theme', 'noborder_dark');
  }
}
</script><script>if (localStorage.getItem('font-size')) {
  document.querySelector('.post-content').style.fontSize = localStorage.getItem('font-size') + 'px';
}
</script>
<script src="/js/theme/tool-bar.js"></script>


<script src="/js/theme/menu.js"></script>


<script src="/js/third-party/clipboard.min.js"></script>


<script src="/js/theme/copy.js"></script>
<script>copyCode();
</script>
<script src="/js/jquery-3.7.1.min.js"></script>


<script src="/js/theme/search.js"></script>
<script>searchFunc('/search.xml', 'search-input', 'search-result');
</script></body></html>